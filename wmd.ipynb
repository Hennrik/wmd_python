{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pyemd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.metrics import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words('english')).union( set(stopwords.words('german')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        self.text   = text[1]\n",
    "        self.id = text[0]\n",
    "        self.avg    = []\n",
    "        self.hash   = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.042436838150024\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "documents = []\n",
    "with open('/data/Evaluations/training_set/tokens100.csv') as documentTokens:\n",
    "    for tokens in documentTokens:\n",
    "        line = tokens.strip().split('\\t')\n",
    "#         postingId = line[0]\n",
    "#         doc = line[1]\n",
    "        document = Document(line)\n",
    "        documents.append(document)\n",
    "        \n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592.2192177772522\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "nbow = CountVectorizer(stop_words = stopwords_set)\n",
    "nbow.fit([doc.text for doc in documents])\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words={'was', 'einiges', 'how', 'for', 'mich', 'demselben', 'meines', 'then', 'so', 'dieser', 'as', 'any', 'meinem', 'you', 'muss', 'andere', 'why', 'been', 'zur', 'daß', 'where', 'by', 'allen', 'yourself', 'wasn', 'da', 'keine', 'vor', 'alle', 'er', 'nun', 'auch', 'did', 'deines', 'wie', 'woll...', 'noch', 'didn', 'selbst', 'against', 'aller', 'is', 'würden', 'auf', 'derer', 'einmal', 'musste'},\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.74746608734131\n"
     ]
    }
   ],
   "source": [
    "# load word2vec model vectorSize = 200\n",
    "start = time.time()\n",
    "model200 = Word2Vec.load('/data/word2vec_new/word2vec_models/w2vmodel_200')\n",
    "vocabulary = set(model200.index2word)\n",
    "names = nbow.get_feature_names()\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.782058000564575\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "filtered = []\n",
    "for document in documents:\n",
    "    if len(document.text.split()) > 30:\n",
    "        filtered += [document]\n",
    "print(time.time() - start)\n",
    "filtered_dict = {}\n",
    "for document in filtered:\n",
    "    filtered_dict[document.id] = document.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg(doc):\n",
    "    '''\n",
    "    A document is represented by it's average word vector\n",
    "    '''\n",
    "    return np.mean([model200[token] for token in doc.text.split() if token in vocabulary], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219.6014111042023\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for document in filtered:\n",
    "    document.avg = avg(document)\n",
    "    \n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flow_graph_wmd(doc1, doc2):     \n",
    "    v1, v2    = nbow.transform([doc1, doc2])   \n",
    "    index     = np.union1d(v1.indices, v2.indices)\n",
    "    \n",
    "    v1  = v1.toarray().ravel()\n",
    "    v2  = v2.toarray().ravel()\n",
    "    \n",
    "    n         = len(index)    \n",
    "    index_map = [(index[i], i) for i in range(n) if names[index[i]] in vocabulary]\n",
    "    source    = np.zeros(n)\n",
    "    sink      = np.zeros(n)\n",
    "    vecs      = np.zeros(shape = (n, 200))\n",
    "    \n",
    "    for i, j in index_map:\n",
    "        source[j] = v1[i]\n",
    "        sink[j]   = v2[i]\n",
    "        vecs[j]   = model200[names[i]]\n",
    "#         print(names[i])\n",
    "    sum_source = sum(source)\n",
    "    sum_sink = sum(sink)\n",
    "    if sum_source == 0:\n",
    "        sum_source = 1\n",
    "    if sum_sink == 0:\n",
    "        sum_sink = 1\n",
    "    return (source / sum_source, sink / sum_sink, vecs)\n",
    "\n",
    "def flow_graph_rwmd(doc1, doc2):     \n",
    "    v1, v2    = nbow.transform([doc1, doc2])   \n",
    "    index     = np.union1d(v1.indices, v2.indices)\n",
    "    \n",
    "    v1  = v1.toarray().ravel()\n",
    "    v2  = v2.toarray().ravel()\n",
    "\n",
    "    n         = len(index)    \n",
    "#     index_map = [index[i] for i in range(n) if names[index[i]] in vocabulary]\n",
    "    index_map = [i for i in index if names[i] in vocabulary]\n",
    "    source    = np.zeros(len(index_map))\n",
    "    sink      = np.zeros(len(index_map))\n",
    "    vecs      = np.zeros(shape = (len(index_map), 200))\n",
    "\n",
    "    for j, i in enumerate(index_map):\n",
    "        source[j] = v1[i]\n",
    "        sink[j]   = v2[i]\n",
    "        vecs[j]   = model200[names[i]]\n",
    "#         print(names[i])\n",
    "    sum_source = sum(source)\n",
    "    sum_sink = sum(sink)\n",
    "    if sum_source == 0:\n",
    "        sum_source = 1\n",
    "    if sum_sink == 0:\n",
    "        sum_sink = 1\n",
    "    return (source / sum_source, sink / sum_sink, vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 5.86 ms\n"
     ]
    }
   ],
   "source": [
    "doc1 = documents[1].text\n",
    "doc2 = documents[2].text\n",
    "%time source, sink, vecs = flow_graph_rwmd(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emd(doc1, doc2): \n",
    "    source, sink, vecs = flow_graph_wmd(doc1, doc2)\n",
    "    if len(vecs) > 2:\n",
    "        weights = euclidean_distances(vecs)\n",
    "#         print(weights)\n",
    "        return pyemd.emd(source, sink, weights)\n",
    "    else:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.89 s, sys: 2.74 s, total: 4.63 s\n",
      "Wall time: 488 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30.075525931577488"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time emd(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rwmd(doc1, doc2):\n",
    "    source, sink, vecs = flow_graph_rwmd(doc1, doc2)\n",
    "    weights = euclidean_distances(vecs)\n",
    "    new_weights_dj = []\n",
    "    potential_dj = list(j for j, dj in enumerate(sink) if dj > 0)\n",
    "    new_weights_dj = list(min(weights[i, potential_dj]) for i in range(len(source)))\n",
    "    potential_di = list(i for i, di in enumerate(source) if di > 0)\n",
    "    new_weights_di = list(min(weights[j, potential_di]) for j in range(len(sink)))\n",
    "    rwmd = max(np.dot(new_weights_dj, source), np.dot(new_weights_di, sink))\n",
    "    return rwmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 96 ms, total: 116 ms\n",
      "Wall time: 19 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.60578776575931"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rwmd(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load groundTruth\n",
    "\n",
    "groundTruthRDDraw = sc.textFile('/data/groundTruth/groundTruth.csv')\n",
    "def parseGroundTruth(x):\n",
    "    line = x.split('\\t')\n",
    "    postingId = int(line[0])\n",
    "    similarIds = list(map(lambda s: int(s), line[1].split()))\n",
    "    return postingId, similarIds\n",
    "\n",
    "groundTruthRDD = groundTruthRDDraw.map(parseGroundTruth)\n",
    "groundTruth = groundTruthRDD.collectAsMap()\n",
    "sample_idsRDD = groundTruthRDD.map(lambda x: x[0])\n",
    "sample_ids = sample_idsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions():\n",
    "    \n",
    "    qid     = random.randrange(0, len(filtered))\n",
    "#     query   = filtered[qid]\n",
    "    while int(filtered[qid].id) not in sample_ids:\n",
    "        qid = random.randrange(0, len(filtered))\n",
    "    query = filtered[qid]\n",
    "    wcd = {}\n",
    "    \n",
    "# Check Average (Prooven Lower Bound to EMD)\n",
    "    for i in range(len(filtered)):\n",
    "        lb = euclidean(query.avg, filtered[i].avg)\n",
    "        wcd[filtered[i].id] = lb\n",
    "                 \n",
    "# wcd_sorted = sorted(wcd.items(), key=lambda x: x[1])[1:100001]\n",
    "    wcd_sorted = sorted(wcd.items(), key=lambda x: x[1])[1:50001]\n",
    "    wcd_documents = [(x[0], filtered_dict[x[0]]) for x in wcd_sorted]\n",
    "    wcd_20 = wcd_sorted[:20]\n",
    "                \n",
    "    wmd_20 = [(x[0], emd(filtered_dict[query.id], filtered_dict[x[0]])) for x in  wcd_20]\n",
    "    kth = max(wmd_20, key=lambda x: x[1])\n",
    "    keys = set(map(lambda x: x[0], wmd_20))\n",
    "    num_prune = 0\n",
    "    count = 0\n",
    "    test = 0\n",
    "    for key, value in wcd_documents:\n",
    "        if key not in keys:\n",
    "            if rwmd(query.text, value) < kth[1]:\n",
    "                test += 1\n",
    "                new_wmd = emd(query.text, value)\n",
    "                if new_wmd < kth[1]:\n",
    "#                 print(1)\n",
    "                    wmd_20.remove(kth)\n",
    "                    wmd_20.append((key, new_wmd))\n",
    "                    kth = max(wmd_20, key=lambda x: x[1])\n",
    "                    keys = set(map(lambda x: x[0], wmd_20))\n",
    "            else:\n",
    "                num_prune += 1\n",
    "        count += 1  \n",
    "    print('pruned %f' % (num_prune/len(wcd_documents)))\n",
    "    wmd_20 = sorted(wmd_20, key=lambda x: x[1])\n",
    "    prediction = list(map(lambda x: x[0],wmd_20))\n",
    "    return (int(query.id), prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned 0.993320\n",
      "CPU times: user 32min 26s, sys: 1h 41min 56s, total: 2h 14min 23s\n",
      "Wall time: 15min 4s\n",
      "pruned 0.986340\n",
      "CPU times: user 51min 36s, sys: 2h 50min 9s, total: 3h 41min 46s\n",
      "Wall time: 22min 50s\n",
      "pruned 0.998600\n",
      "CPU times: user 59min 35s, sys: 3h 23min 55s, total: 4h 23min 31s\n",
      "Wall time: 24min 45s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-ccb448f1b938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time index, predictions = getPredictions()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msample_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-dcf9ab10647f>\u001b[0m in \u001b[0;36mgetPredictions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrwmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mtest\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mnew_wmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mnew_wmd\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#                 print(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5c7d088e641d>\u001b[0m in \u001b[0;36memd\u001b[1;34m(doc1, doc2)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#         print(weights)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpyemd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     %time index, predictions = getPredictions()\n",
    "#     sample_predictions.append((index, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
